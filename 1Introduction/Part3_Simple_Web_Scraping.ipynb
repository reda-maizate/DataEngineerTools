{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de commencer, parcourer le fichier README.rst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requête HTTP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un requête HTTP est une requête basé sur le protocole TCP, elle fait partie de la couche application de la couche OSI. Elle permet d'accéder aux données mise à disposition sur une adresse IP (ou url résolue par un DNS) et un port. \n",
    "\n",
    "Les deux ports les plus utilisé dans le web sont le 80 pour les sites en HTTP et le 443 pour les sites en HTTPS. HTTPS est une variable du protocole HTTP basé sur le protocole TLS.\n",
    "\n",
    "Il existe de nombreux types de requêtes selon la convention `REST`: \n",
    "- GET\n",
    "- POST\n",
    "- PUT \n",
    "- DELETE\n",
    "- UPDATE.\n",
    "\n",
    "Dans notre cas nous allons utiliser la plupart du temps des GET et potentiellement des POST. \n",
    "- Le GET permet comme sont nom l'indique de récupérer des informations en fonction de certain paramètres. \n",
    "- Le POST nécéssite un envoie de données pour récupérer des données. Le body du post est, la plupart du temps, envoyé sous la forme d'un objet JSON.\n",
    "\n",
    "Ces requêtes encapsulent un certain nombre de paramètres qui permettent soient d'identifier une provenance et un utilisateur ou de réaliser différentes actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://www.esiee.fr/\"\n",
    "response = requests.get(url)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe deux méthodes pour récupérer le contenu de la page :\n",
    "\n",
    "- `response.text` qui permet de retourner le texte sous la forme d'une chaine de charactères.\n",
    "- `response.content` qui permet de récupérer le contenu de la page sous la forme de bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour récupérer les 1000 premiers charactères de la page :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<!--[if lt IE 7]>      <html class=\"no-js lt-ie9 lt-ie8 lt-ie7\"> <![endif]-->\\n<!--[if IE 7]>         <html class=\"no-js lt-ie9 lt-ie8\"> <![endif]-->\\n<!--[if IE 8]>         <html class=\"no-js lt-ie9\"> <![endif]-->\\n<!--[if IE 9]>         <html class=\"no-js ie9\"> <![endif]-->\\n<!--[if gt IE 9]><!--> <html class=\"no-js\"> <!--<![endif]-->\\n<head profile=\"http://www.w3.org/1999/xhtml/vocab\">\\n\\t<!-- Google Tag Manager -->\\n\\t<script>\\n\\t\\t(function(w,d,s,l,i){\\n\\t\\t\\tw[l]=w[l]||[];w[l].push({\\'gtm.start\\':new Date().getTime(),event:\\'gtm.js\\'});\\n\\t\\t\\tvar f=d.getElementsByTagName(s)[0],\\tj=d.createElement(s),dl=l!=\\'dataLayer\\'?\\'&l=\\'+l:\\'\\';\\n\\t\\t\\tj.async=true;\\n\\t\\t\\tj.src=\\'https://www.googletagmanager.com/gtm.js?id=\\'+i+dl;f.parentNode.insertBefore(j,f);\\n\\t\\t\\t}\\n\\t\\t)\\n\\t\\t(window,document,\\'script\\',\\'dataLayer\\',\\'GTM-MQF5LJB\\');\\n\\t</script>\\n\\t<!-- End Google Tag Manager -->\\n  <meta name=\"google-site-verification\" content=\"JnG7DTdhQuWTeSHlWC63CeWpb3WValiOorksYjoYOWI\" />\\n  <meta http-equiv=\"Content-Type\" content=\"text/ht'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour récupérer les headers HTTP de la réponse :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': 'Wed, 24 Mar 2021 08:36:39 GMT', 'Server': 'Apache/2.4.25 (Debian)', 'Expires': 'Sun, 19 Nov 1978 05:00:00 GMT', 'Cache-Control': 'no-cache, must-revalidate', 'X-Content-Type-Options': 'nosniff', 'Content-Language': 'fr', 'X-Frame-Options': 'SAMEORIGIN', 'X-Generator': 'Drupal 7 (http://drupal.org)', 'Vary': 'Accept-Encoding', 'Content-Encoding': 'gzip', 'Content-Length': '16360', 'Keep-Alive': 'timeout=5, max=150', 'Connection': 'Keep-Alive', 'Content-Type': 'text/html; charset=utf-8'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut modifier les paramêtres de la requête et/ou ses headers. On peut par exemple ajouter un UserAgent et un timeout de 10 secondes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<!--[if lt IE 7]>      <html class=\"no-js lt-ie9 lt-ie8 lt-ie7\"> <![endif]-->\\n<!--[if IE 7]>         <html class=\"no-js lt-ie9 lt-ie8\"> <![endif]-->\\n<!--[if IE 8]>         <html class=\"no-js lt-ie9\"> <![endif]-->\\n<!--[if IE 9]>         <html class=\"no-js ie9\"> <![endif]-->\\n<!--[if gt IE 9]><!--> <html class=\"no-js\"> <!--<![endif]-->\\n<head profile=\"http://www.w3.org/1999/xhtml/vocab\">\\n\\t<!-- Google Tag Manager -->\\n\\t<script>\\n\\t\\t(function(w,d,s,l,i){\\n\\t\\t\\tw[l]=w[l]||[];w[l].push({\\'gtm.start\\':new Date().getTime(),event:\\'gtm.js\\'});\\n\\t\\t\\tvar f=d.getElementsByTagName(s)[0],\\tj=d.createElement(s),dl=l!=\\'dataLayer\\'?\\'&l=\\'+l:\\'\\';\\n\\t\\t\\tj.async=true;\\n\\t\\t\\tj.src=\\'https://www.googletagmanager.com/gtm.js?id=\\'+i+dl;f.parentNode.insertBefore(j,f);\\n\\t\\t\\t}\\n\\t\\t)\\n\\t\\t(window,document,\\'script\\',\\'dataLayer\\',\\'GTM-MQF5LJB\\');\\n\\t</script>\\n\\t<!-- End Google Tag Manager -->\\n  <meta name=\"google-site-verification\" content=\"JnG7DTdhQuWTeSHlWC63CeWpb3WValiOorksYjoYOWI\" />\\n  <meta http-equiv=\"Content-Type\" content=\"text/ht'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "response = requests.get(url, headers=headers, timeout = 10)\n",
    "response.content[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1\n",
    "\n",
    "- Créer une classe Python permettant de faire des requêtes HTTP.\n",
    "- Cette classe doit utiliser toujours le même UserAgent.\n",
    "- Le TimeOut sera spécifié à chaque appelle avec une valeur par défaut.\n",
    "- Un mécanisme de retry sera mis en place de façon recursive.\n",
    "\n",
    "## Exercice 2\n",
    "\n",
    "- Faire une fonction permettant de supprimer tous les espaces supperflus d'une string\n",
    "- Faire une fonction qui prend une string html et renvois une string intelligible (enlever les caractères spéciaux,\n",
    "- Récupérer le domaine en fonction d'un url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "class requetesHTTP:\n",
    "    def __init__(self):\n",
    "            self.headers = 'Example'\n",
    "        \n",
    "    def get_url(self, url, timeout=10, retry=4):\n",
    "        if retry < 1:\n",
    "            return None\n",
    "        headers = {\n",
    "            \"User-Agent\": self.headers\n",
    "        }\n",
    "        try:\n",
    "            res = requests.get(url, headers=headers, timeout=timeout)\n",
    "            if res.status_code != 200:\n",
    "                raise requests.exceptions.BaseHTTPError\n",
    "            return res\n",
    "        except requests.exceptions.ConnectTimeout:\n",
    "            print(\"Timeout\")\n",
    "            self.get_url(url, timeout=timeout+1, retry=retry-1)\n",
    "        except requests.exceptions.BaseHTTPError:\n",
    "            print(\"Error!\")\n",
    "            self.get_url(url, timeout=timeout, retry=retry-1)\n",
    "    \n",
    "\n",
    "test = requetesHTTP().get_url(\"https://google.fr/\", timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def delSpacesStr(text):\n",
    "    try:\n",
    "        return text.strip()\n",
    "    except AttributeError:\n",
    "        return \"Error: The text you imported is not a text!\"\n",
    "\n",
    "def cleanStrHtml(htmlline):\n",
    "    try:\n",
    "        cleaned = re.sub(r\"[^a-zA-Z0-9]\",\"\",htmlline)\n",
    "        return cleaned\n",
    "    except AttributeError:\n",
    "        return \"Error: There is a probleme with the HTML line you gave!\"\n",
    "    except TypeError:\n",
    "        return \"Error: The type of URL is not supported!\"\n",
    "\n",
    "def getDomain(url):\n",
    "    try:\n",
    "        domain = urlparse(url).netloc\n",
    "        return domain\n",
    "    except AttributeError:\n",
    "        return \"Error: There is a problem with the URL you gave!\"\n",
    "    except TypeError:\n",
    "        return \"Error: The type of URL is not supported!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oui bonjour\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Error: The text you imported is not a text!'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(delSpacesStr(\"         Oui bonjour             \"))\n",
    "delSpacesStr(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "htmlBonsoirnonhtml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Error: The type of URL is not supported!'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cleanStrHtml(\"<html> Bonsoir non </html>\"))\n",
    "cleanStrHtml(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Error: There is a problem with the URL you gave!'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(getDomain(\"https://google.com/nameofthewebsite\"))\n",
    "getDomain(55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploitation du HTML  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, il faut récupérer le code HTML d'un site web à partir d'une requête. Lorsque vous avez récupéré le texte d'un site il faut le parser. Pour cela, on utilise BeautifulSoup qui permet de transformer la structure HTML en objet Python. Cela permet de récupérer efficacement les données qui nous intéresse.\n",
    "\n",
    "Pour les webmasters, le blocage le plus souvent mis en place et un blocage sur le User-Agent. Le User-Agent est un paramètre intégré dans la requête HTTP réalisé par le Navigateur pour envoyer au front des informations basiques :\n",
    "\n",
    "- la version du Navigateur,\n",
    "- la version de l'OS\n",
    "- Le type de gestionnaire graphique (Gecko)\n",
    "- le type de device utilisé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple de User Agent :  \n",
    "\n",
    "`Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons à utiliser `BeautifulSoup`, pour l'installer : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in d:\\users\\redad\\miniconda3\\envs\\artificial_env\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\users\\redad\\miniconda3\\envs\\artificial_env\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\users\\redad\\miniconda3\\envs\\artificial_env\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Requirement already satisfied: lxml in d:\\users\\redad\\miniconda3\\envs\\artificial_env\\lib\\site-packages (4.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install  lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour transformer une requête (requests) en objet BeautifulSoup :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il se peut qu'un message d'erreur arrive à ce point là si vous n'avez pas la librarie `lxml` installée, pour se faire vous avez juste à lancer la commande suivante : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in d:\\users\\redad\\miniconda3\\envs\\artificial_env\\lib\\site-packages (4.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour trouver tous les liens d'une page on récupère la balise `a` qui permet de gérer les liens en HTML  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://esiee.agires.com/\" target=\"_blank\">\n",
       " <!-- scald=2864:full --><img alt=\"Taxe d'apprentissage 2021\" height=\"600\" src=\"https://www.esiee.fr/sites/default/files/thumbnails/image/banniere-taxe-31052021.gif\" title=\"Taxe d'apprentissage 2021\" width=\"160\"/><!-- END scald=2864 -->\n",
       " </a>, <a href=\"#\">\n",
       " <i class=\"icon-parametres\"></i>\n",
       " </a>, <a href=\"https://gmail.com\" target=\"_blank\" title=\"Webmail ESIEE Paris\"><i><img alt=\"\" src=\"https://www.esiee.fr/sites/default/files/menu_icons/menu_icon_950.png\"/> </i><span>Webmail ESIEE Paris</span></a>, <a href=\"https://planif.esiee.fr/direct/\" target=\"_blank\" title=\"Emploi du temps général\"><i><img alt=\"\" src=\"https://www.esiee.fr/sites/default/files/menu_icons/menu_icon_1331.png\"/> </i><span>Emploi du temps général</span></a>, <a href=\"https://planif.esiee.fr/jsp/custom/esiee/easyMyPlanning.jsp\" target=\"_blank\" title=\"Emploi du temps individuel\"><i><img alt=\"\" src=\"https://www.esiee.fr/sites/default/files/menu_icons/menu_icon_1332.png\"/> </i><span>Emploi du temps individuel</span></a>, <a href=\"https://intra.esiee.fr\" target=\"_blank\" title=\"Extranet\"><i><img alt=\"\" src=\"https://www.esiee.fr/sites/default/files/menu_icons/menu_icon_951.png\"/> </i><span>Extranet</span></a>, <a href=\"https://esiee.blackboard.com\" target=\"_blank\" title=\"iCampus\"><i><img alt=\"\" src=\"https://www.esiee.fr/sites/default/files/menu_icons/menu_icon_1311.png\"/> </i><span>iCampus</span></a>, <a href=\"http://e5.onthehub.com/WebStore/Welcome.aspx?vsro=8&amp;ws=45AD823E-799B-E011-969D-0030487D8897&amp;JSEnabled=1\" target=\"_blank\" title=\"Microsoft DreamSpark\"><i><img alt=\"\" src=\"https://www.esiee.fr/sites/default/files/menu_icons/menu_icon_1696.png\"/> </i><span>Microsoft DreamSpark</span></a>, <a href=\"/en\">\n",
       " <i>\n",
       " <img alt=\"English\" src=\"/sites/all/themes/custom/esiee_theme/assets/images/flag-en.png\"/>\n",
       " </i>\n",
       " </a>, <a href=\"https://www.facebook.com/esieeparis\" target=\"_blank\">\n",
       " <i class=\"fa fa-facebook\"></i>\n",
       " </a>]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"a\")[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut préciser la classe HTML voulue  pour l'ensemble des `a`:\n",
    "\n",
    "```python\n",
    "soup.find_all(class_=\"<CLASS_NAME>\")[0:10]\n",
    "```\n",
    "\n",
    "Ici par exemple: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"slide slide-content\">\n",
       " <span class=\"slide-content-date inline-block\"><span class=\"date-display-single\">24.03.2021</span></span>\n",
       " <span class=\"slide-content-theme inline-block is-uppercase\">Actualités</span>\n",
       " <div class=\"clearfix\"></div>\n",
       " <div class=\"slide-content-img pull-left\"><!-- scald=2918:news_thumbnail --><img alt=\"Etudiants ESIEE Paris - Rue\" height=\"90\" src=\"https://www.esiee.fr/sites/default/files/styles/news/public/thumbnails/image/visuel-etudiants-421-web-920x600.jpg?itok=VPajJgAI\" title=\"Etudiants ESIEE Paris - Rue\" width=\"120\"/><!-- END scald=2918 --></div>\n",
       " <span class=\"slide-content-title\"><a class=\"is-uppercase\" href=\"/fr/actualite/webinaire-special-apprentissage-2021\">[Webinaire Spécial Apprentissage] Trouver son contrat d’apprentissage !</a></span>\n",
       " <div class=\"clearfix\"></div>\n",
       " <p class=\"slide-content-desc\">Assistez au webinaire Spécial Apprentissage en direct live sur notre chaîne Youtube ! Mercredi 24 mars à 18h.</p> </div>,\n",
       " <div class=\"slide slide-content\">\n",
       " <span class=\"slide-content-date inline-block\"><span class=\"date-display-single\">11.03.2021</span></span>\n",
       " <span class=\"slide-content-theme inline-block is-uppercase\">Actualités</span>\n",
       " <div class=\"clearfix\"></div>\n",
       " <div class=\"slide-content-img pull-left\"><!-- scald=2868:news_thumbnail --><img alt=\"Visite école ESIEE Paris\" height=\"90\" src=\"https://www.esiee.fr/sites/default/files/styles/news/public/thumbnails/image/generique-visites-210x140.jpg?itok=7WQsZVWf\" title=\"Visite école ESIEE Paris\" width=\"120\"/><!-- END scald=2868 --></div>\n",
       " <span class=\"slide-content-title\"><a class=\"is-uppercase\" href=\"/fr/actualite/visites-ecole-ingenieurs-esiee-paris\">Visites guidées en visio : pour bien choisir votre école d'ingénieurs</a></span>\n",
       " <div class=\"clearfix\"></div>\n",
       " <p class=\"slide-content-desc\">Prenez rendez-vous pour une visite de l'école à distance, guidé par un étudiant sur-place.</p> </div>,\n",
       " <div class=\"slide slide-content\">\n",
       " <span class=\"slide-content-date inline-block\"><span class=\"date-display-single\">11.03.2021</span></span>\n",
       " <span class=\"slide-content-theme inline-block is-uppercase\">Admissions</span>\n",
       " <div class=\"clearfix\"></div>\n",
       " <div class=\"slide-content-img pull-left\"><!-- scald=2872:news_thumbnail --><img alt=\"visuel-admissions-photo-505-web-920x600.jpg\" height=\"90\" src=\"https://www.esiee.fr/sites/default/files/styles/news/public/thumbnails/image/visuel-admissions-photo-505-web-920x600.jpg?itok=KheoKV2i\" title=\"Admissions Bac +2 / +3 : accédez à la plateforme des admissions ESIEE Paris\" width=\"120\"/><!-- END scald=2872 --></div>\n",
       " <span class=\"slide-content-title\"><a class=\"is-uppercase\" href=\"/fr/actualite/admisions-bac2-bac3\">Admissions Bac +2 / +3 : accédez à la plateforme des admissions ESIEE Paris</a></span>\n",
       " <div class=\"clearfix\"></div>\n",
       " <p class=\"slide-content-desc\">Vous êtes en bac+2/+3 scientifique ? Vous pouvez accéder au cycle ingénieur à ESIEE Paris soit par la voie classique ou en apprentissage.</p> </div>,\n",
       " <div class=\"slide slide-content\">\n",
       " <span class=\"slide-content-date inline-block\"><span class=\"date-display-single\">12.03.2021</span></span>\n",
       " <span class=\"slide-content-theme inline-block is-uppercase\">Classement</span>\n",
       " <div class=\"clearfix\"></div>\n",
       " <div class=\"slide-content-img pull-left\"><!-- scald=2895:news_thumbnail --><img alt=\"logohappyatschool.jpg\" height=\"90\" src=\"https://www.esiee.fr/sites/default/files/styles/news/public/thumbnails/image/visuel-classementhas-2021.jpg?itok=fgcS4Fk7\" title=\"logohappyatschool.jpg\" width=\"120\"/><!-- END scald=2895 --></div>\n",
       " <span class=\"slide-content-title\"><a class=\"is-uppercase\" href=\"/fr/actualite/esiee-11e-classement-happyatschool-ingenieur\">ESIEE Paris 11e meilleure école d’ingénieurs Classement HappyAtSchool® 2021</a></span>\n",
       " <div class=\"clearfix\"></div>\n",
       " <p class=\"slide-content-desc\">Dans un contexte compliqué, particulièrement éprouvant pour les étudiants, ESIEE Paris se distingue au classement HappyAtSchool 2021.</p> </div>,\n",
       " <div class=\"slide slide-content\">\n",
       " <span class=\"slide-content-date inline-block\"><span class=\"date-display-single\">18.03.2021</span></span>\n",
       " <span class=\"slide-content-theme inline-block is-uppercase\">Evènements</span>\n",
       " <div class=\"clearfix\"></div>\n",
       " <div class=\"slide-content-img pull-left\"><!-- scald=2917:news_thumbnail --><img alt=\"COP2 étudiante - 10 et 11 avril 2021\" height=\"90\" src=\"https://www.esiee.fr/sites/default/files/styles/news/public/thumbnails/image/visuel-cop2-web-920x600.jpg?itok=uf2ajhK_\" title=\"COP2 étudiante - 10 et 11 avril 2021\" width=\"120\"/><!-- END scald=2917 --></div>\n",
       " <span class=\"slide-content-title\"><a class=\"is-uppercase\" href=\"/fr/actualite/COP2-etudiante-les-etudiants-esiee-engages-transition-ecologique\">COP2 : les étudiants ESIEE Paris s’engagent pour la transition écologique avec l’Université Gustave Eiffel</a></span>\n",
       " <div class=\"clearfix\"></div>\n",
       " <p class=\"slide-content-desc\">Dans la situation d’urgence environnementale actuelle, tous s’accordent à dire qu’il est primordial d’agir au plus vite.</p> </div>]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(class_=\"slide\")[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour récupérer le text sans les balises HTML :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nESIEE Paris, l’école de l’innovation technologique | Grande école d’ingénieurs | ESIEE Paris\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLes outils ESIEE Paris Webmail ESIEE Paris Emploi du temps général Emploi du temps individuel Extranet iCampus Microsoft DreamSpark \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n menu\\nFormations\\n\\n\\nRETOUR menu\\nFormations ESIEE ParisIngénieur\\n\\n\\nIngénieur\\nRETOUR Formations\\nIngénieur ESIEE ParisPremier cycleLe cycle ingénieur\\n\\n\\nLe cycle ingénieur\\nRETOUR Ingénieur\\nLe cycle ingénieur ESIEE ParisEnseignements de 1ère annéeEnseignements de 2e et 3e annéeProfils métiersFilières\\n\\n\\nFilières\\nRETOUR Ingénieur\\n9 filières, 1 diplômeInformatiqueCybersécuritéDatascience et intelligence artificielleArtificial Intelligence and CybersecuritySystèmes embarquésSystèmes électroniques intelligentsGénie industrielBiotechnologies et e-santéEnergieDoubles-diplômesEmplois et salairesFrais de scolarité - Aides financièresStagesAdmissionsContactIngénieur par apprentissage\\n\\n\\nIngén'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.text[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice\n",
    "### Exercice 3\n",
    "\n",
    "Améliorer la classe développé précédemment.\n",
    "\n",
    "- Ajouter une méthode pour récupérer l'objet soup d'un url\n",
    "- Récupérer une liste de User Agent et effectuer une rotation aléatoire sur celui à utiliser\n",
    "- Utiliser cette classe pour parser une page HTML et récupérer : le titre, tous les H1 (si ils existent), les liens vers les images, les liens sortants vers d'autres sites, et le texte principal.\n",
    "\n",
    "Parsing d'un sitemaps pour récupérer une listes de liens avec les informations disponibles. -> Stocker dans un dictionnaire et dans un fichier JSON local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from random import choice\n",
    "import json\n",
    "\n",
    "class requetesHTTP:\n",
    "    def __init__(self):\n",
    "        self.headers = 'Example'\n",
    "        self.sitemap = dict()\n",
    "        \n",
    "    def get_url(self, url, timeout=10, retry=4, params=None):\n",
    "        if retry < 1:\n",
    "            return None\n",
    "        headers = {\n",
    "            \"User-Agent\": self.random_ua()\n",
    "        }\n",
    "        try:\n",
    "            res = requests.get(url, headers=headers, timeout=timeout, params=params)\n",
    "            if res.status_code != 200:\n",
    "                raise requests.exceptions.BaseHTTPError\n",
    "            return res\n",
    "        except requests.exceptions.ConnectTimeout:\n",
    "            print(\"Timeout\")\n",
    "            self.get_url(url, timeout=timeout+1, retry=retry-1, params=params)\n",
    "        except requests.exceptions.BaseHTTPError:\n",
    "            print(\"Error!\")\n",
    "            self.get_url(url, timeout=timeout, retry=retry-1, params=params)\n",
    "    \n",
    "    def get_soup(self, res):\n",
    "        try:\n",
    "            self.soup = BeautifulSoup(res.text)\n",
    "        except Exception:\n",
    "            print(\"Error: There is something not working!\")\n",
    "    \n",
    "    def random_ua(self):\n",
    "        all_ua = [\n",
    "                 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36',\n",
    "                 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36',\n",
    "                 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36',\n",
    "                 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1) AppleWebKit/602.2.14 (KHTML, like Gecko) Version/10.0.1 Safari/602.2.14',\n",
    "                 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36',\n",
    "                 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.98 Safari/537.36',\n",
    "                 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.98 Safari/537.36',\n",
    "                 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36',\n",
    "                 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36',\n",
    "                 'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0'\n",
    "        ]\n",
    "        \n",
    "        self.headers = choice(all_ua)\n",
    "        return self.headers\n",
    "    \n",
    "    def get_title(self):\n",
    "        self.sitemap[\"title\"] = self.soup.find(\"title\").text\n",
    "        return self.sitemap[\"title\"]\n",
    "    \n",
    "    def get_h1(self):\n",
    "        self.sitemap[\"h1\"] = [h1.text for h1 in self.soup.find_all(\"h1\")]\n",
    "        return self.sitemap[\"h1\"]\n",
    "    \n",
    "    def get_link_img(self):\n",
    "        self.sitemap[\"link_img\"] = [link.get(\"src\") for link in self.soup.find_all(\"img\")]\n",
    "        return self.sitemap[\"link_img\"]\n",
    "    \n",
    "    def get_link_website(self):\n",
    "        self.sitemap[\"link_website\"] = [link.get(\"href\") for link in self.soup.find_all(\"a\")]\n",
    "        return self.sitemap[\"link_website\"]\n",
    "    \n",
    "    def get_content(self):\n",
    "        self.sitemap[\"content\"] = [content.text for content in self.soup.find_all(\"p\")]\n",
    "        return self.sitemap[\"content\"]\n",
    "    \n",
    "    def save_to_json(self, filename):\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(self.sitemap, f)\n",
    "    \n",
    "    def scrape_the_website(self, filename):\n",
    "        self.get_title()\n",
    "        self.get_h1()\n",
    "        self.get_link_img()\n",
    "        self.get_link_website()\n",
    "        self.get_content()\n",
    "        self.save_to_json(filename)\n",
    "        \n",
    "test = requetesHTTP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test.get_url(\"https://github.com/reda-maizate/DataEngineerTools/tree/master/1Introduction\", timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.get_soup(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st version\n",
    "test.scrape_the_website(\"mydata.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploitation des appels d'API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Losque le front du site récupère des données sur une API géré par le back, un appel d'API est réalisé. Cet appel est recensé dans les appels réseaux. Il est alors possible de re-jouer cet appel pour récupérer à nouveau les données. Il est très facile de récupérer ces appels dans l'onglet Network de la console développeur de Chrome ou FireFox. La console vous permet de copier le code CURL pour effectuée et vous pouvez ensuite la transformer en code Python depuis le site https://curl.trillworks.com/.\n",
    "\n",
    "Souvent les APIs sont bloquées avec certain paramètres. L'API verifie que dans les headers de la requêtes HTTP ces paramètres sont présents : * un token généré à la volée avec des protocole OAuth2 (ou moins développés). * un referer provenant du site web (la source de la requête), très facile à falsifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice \n",
    "### Exercice 4\n",
    "\n",
    "- Utiliser les informations développées plus haut pour récupérer les premiers résultats d'une recherche d'une requête\n",
    "sur Qwant. \n",
    "\n",
    "Tips : \n",
    "\n",
    "- Aller sur https://www.qwant.com/\n",
    "- Ouvrir les outils de développements de Chrome ou Firefox\n",
    "- Onglet Network\n",
    "- Fouiller dans les requêtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BONJOUR : Définition de BONJOUR',\n",
       " 'Bonjour',\n",
       " 'Apprendre le français – Cours et exercices gratuits avec Bonjour de France',\n",
       " 'Bonjour - CosaVostra',\n",
       " 'Bonjour Paris : Actualités en temps réel de Paris | BFM Paris sur BFMTV.com']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = (\n",
    "    ('count', '10'),\n",
    "    ('q', 'bonjour'),\n",
    "    ('t', 'web'),\n",
    "    ('device', 'desktop'),\n",
    "    ('safesearch', '1'),\n",
    "    ('locale', 'fr_FR'),\n",
    "    ('uiv', '4'),\n",
    ")\n",
    "\n",
    "response = requests.get('https://api.qwant.com/api/search/web', headers=headers, params=params)\n",
    "page = json.loads(response.text)\n",
    "\n",
    "[page[\"data\"][\"result\"][\"items\"][i][\"title\"] for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice Final  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice Final\n",
    "Utilisez tout ce que vous avez appris pour récupérer des articles de News avec une catégorie. Il est souvent intéressant de partir des flux RSS pour commencer :\n",
    "\n",
    "Les données doivent comprendre :\n",
    "- Le texte important propre\n",
    "- L'url\n",
    "- Le domaine\n",
    "- la catégorie\n",
    "- Le titre de l'article\n",
    "- Le titre de la page\n",
    "- (Facultatif) : les images\n",
    "\n",
    "Tips : \n",
    "\n",
    "- Taper le nom de votre média favoris + RSS (par exemple : https://www.lemonde.fr/rss/)\n",
    "- Aller dans le DOM de la page \n",
    "- Trouver les catégories et les liens vers les articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemonde_rss(categorie):\n",
    "    article_list = []\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(\"https://www.lemonde.fr/rss/\"+categorie+\".xml\")\n",
    "        soup = BeautifulSoup(r.content)\n",
    "        articles = soup.find_all(\"item\")\n",
    "\n",
    "        for a in articles:\n",
    "            title = a.find('title').text\n",
    "            link = a.find('guid').text\n",
    "            published = a.find('pubdate').text\n",
    "            img = a.find(\"media:content\").get(\"url\")\n",
    "            article = {\n",
    "                'title': title,\n",
    "                'link': link,\n",
    "                'categorie': categorie,\n",
    "                'img': img,\n",
    "                'published': published\n",
    "                }\n",
    "            article_list.append(article)\n",
    "        return article_list\n",
    "    except Exception:\n",
    "        print(\"Error!\")\n",
    "        \n",
    "def save_to_txt(article_list):\n",
    "    with open('articles.txt', 'w') as outfile:\n",
    "        json.dump(article_list, outfile)\n",
    "    \n",
    "article_list = get_lemonde_rss(\"en_continu\")\n",
    "save_to_txt(article_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
